{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f14be137",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer \n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import BayesianRidge,Lasso,LassoCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor,AdaBoostRegressor,GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor,StackingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import cross_val_score,train_test_split,GridSearchCV,KFold\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy import stats\n",
    "from sklearn import feature_selection\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler,RobustScaler,PowerTransformer\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RationalQuadratic\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "def split_data(X_train,y_train) :\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_train, y_train,test_size = 0.25, random_state = 43)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def standardize_data(X_train,X_test) :\n",
    "    s = StandardScaler()\n",
    "    r_train = RobustScaler()\n",
    "    r_test = RobustScaler()\n",
    "    \n",
    "    p_train = PowerTransformer()\n",
    "    r_train.fit(X_train)\n",
    "    r_test.fit(X_test)\n",
    "    \n",
    "    scaled_train_data = r_train.transform(X_train)\n",
    "    scaled_test_data = r_train.transform(X_test)\n",
    "    \n",
    "    \n",
    "    return scaled_train_data,scaled_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "493aa6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv(\"X_test.csv\", index_col=0).values\n",
    "X_train = pd.read_csv(\"X_train.csv\", index_col=0).values\n",
    "y_train = pd.read_csv(\"y_train.csv\", index_col=0).values\n",
    "\n",
    "#X_train, X_test, y_train, y_test = split_data(X_train,y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "483ffa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define some imputers\n",
    "imputers = [\n",
    "    SimpleImputer(missing_values=np.nan, strategy='median'),\n",
    "    IterativeImputer(random_state=0, estimator=BayesianRidge()),\n",
    "    IterativeImputer(random_state=0, estimator=DecisionTreeRegressor(max_features=\"sqrt\", random_state=0)),\n",
    "    IterativeImputer(random_state=0, estimator=ExtraTreesRegressor(n_estimators=15, random_state=0, max_depth=7, min_samples_leaf=2)),\n",
    "    IterativeImputer(random_state=0, estimator=KNeighborsRegressor(n_neighbors=15)),\n",
    "    KNNImputer(n_neighbors=12, weights=\"uniform\"),\n",
    "    IterativeImputer(random_state=0, estimator=RandomForestRegressor(n_estimators= 35, random_state = 0, max_depth= 30, min_samples_leaf=2))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9a35a0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_0, X_test_0 = imputation(imputers[0], X_train, X_test)\n",
    "\n",
    "X_train_0,X_test_0 = standardize_data(X_train_0,X_test_0)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f5bc5900",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "640d8960",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def lasso(X_train,y_train,X_test) :\n",
    "    pipeline = Pipeline([('scaler',StandardScaler()),('model',Lasso())])\n",
    "    search = GridSearchCV(pipeline,{'model__alpha':np.arange(0.1,10,0.1)},cv = 5, scoring=\"r2\",verbose=3)\n",
    "    search.fit(X_train,y_train)\n",
    "    coefficients = search.best_estimator_.named_steps['model'].coef_\n",
    "    importance = np.abs(coefficients)\n",
    "    X_train = X_train[:,importance > 0]\n",
    "    X_test = X_test[:,importance > 0]\n",
    "    return X_train,X_test\n",
    "\n",
    "def lasso1(X_train,y_train,X_test) :\n",
    "    ls=LassoCV(cv=5)\n",
    "    ls.fit(X_train,y_train)\n",
    "    mask=ls.coef_!=0\n",
    "    X_train=X_train[:,mask]\n",
    "    X_test = X_test[:,mask]\n",
    "    \n",
    "\n",
    "def imputation(imputer, X_train, X_test):\n",
    "    imputer.fit(X_train)\n",
    "    X_train_0 = imputer.transform(X_train)\n",
    "    X_test_0 = imputer.transform(X_test)\n",
    "    return X_train_0, X_test_0\n",
    "\n",
    "def features_selection(X_train, y_train, X_test,  n_features):\n",
    "    from sklearn import feature_selection\n",
    "    model = feature_selection.SelectKBest(score_func=feature_selection.f_regression,k=n_features)\n",
    "    model = model.fit(X_train, y_train)\n",
    "    cols = model.get_support(indices=True)\n",
    "    \n",
    "    return cols\n",
    "\n",
    "def outlier_detection(X_train, y_train):\n",
    "    clf = IsolationForest(max_samples=100, random_state = 4)\n",
    "    preds = clf.fit_predict(X_train)\n",
    "    X_train_1 = X_train[preds==1]\n",
    "    y_train_1 = y_train[preds==1]\n",
    "    return X_train_1, y_train_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7a5badc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XGB():\n",
    "    def __init__(self, X_train, y_train, X_test):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.n_original_features = X_train.shape[1]\n",
    "        self.selected_features = np.arange(self.n_original_features)\n",
    "\n",
    "        #self.outlier_detection(self.selected_features, self.y_train)\n",
    "\n",
    "      \n",
    "        #Use stacking regressor\n",
    "        self.estimators = [('lasso', Lasso(alpha=0.0005, random_state =  0, max_iter=100)),\n",
    "                            ('xgb',XGBRegressor(max_depth=6,# depth of the tree\n",
    "                                    learning_rate=0.08,\n",
    "                                    n_estimators=100,# number of the tree\n",
    "                                    )),\n",
    "                           ('abr',AdaBoostRegressor(random_state=0, n_estimators=100)),\n",
    "                           ('dtr', DecisionTreeRegressor(max_features=\"sqrt\", random_state=0)), \n",
    "                           ('etr', ExtraTreesRegressor(n_estimators=15, random_state=0, max_depth=7, min_samples_leaf=2)),\n",
    "                           ('rfr', RandomForestRegressor(n_estimators= 15, random_state = 0, max_depth= 6, min_samples_leaf=2)),\n",
    "                           ('knr', KNeighborsRegressor(n_neighbors=15)), \n",
    "                           ('gbr', GradientBoostingRegressor(n_estimators = 100,learning_rate=0.05,\n",
    "                                                              max_depth = 10, random_state=0))]\n",
    "\n",
    "        \n",
    "        self.stacked_regressor = StackingRegressor(estimators=self.estimators)\n",
    "        \n",
    "        self.regressor = XGBRegressor(max_depth=17,n_estimators=115,learning_rate=0.07,subsample=0.9,colsample_bytree=0.6,\n",
    "        min_child_weight=7,\n",
    "        gamma=0.6000000000000001,\n",
    "        reg_alpha=0.9,\n",
    "        reg_lambda=0.7000000000000001)\n",
    "        \n",
    "        self.regressor_gauss = GaussianProcessRegressor(kernel = RationalQuadratic(),random_state = 0,normalize_y = True)\n",
    "             \n",
    "\n",
    "        \n",
    "    def feature_selection(self, n_features = 200):\n",
    "        self.regressor.fit(self.X_train, self.y_train)\n",
    "        self.selected_features = np.argsort(self.regressor.feature_importances_)[::-1][:n_features]\n",
    "        return self.selected_features\n",
    "    \n",
    "    def feature_selection_stacked(self, n_features = 200):\n",
    "        self.stacked_regressor.fit(self.X_train, self.y_train)\n",
    "        self.selected_features = np.argsort(self.stacked_regressor.feature_importances_)[::-1][:n_features]\n",
    "        \n",
    "        return self.selected_features\n",
    "\n",
    "    def cross_validation(self, n_split = 8):\n",
    "        ret = cross_val_score(self.regressor, self.X_train[:,self.selected_features], self.y_train, scoring='r2', cv=n_split)\n",
    "        return ret\n",
    "\n",
    "    def predict(self, write2csv = True):\n",
    "        self.regressor_gauss.fit(self.X_train, self.y_train)\n",
    "        pred = self.regressor_gauss.predict(self.X_test)\n",
    "\n",
    "        if write2csv is True:\n",
    "            submission = np.hstack([np.arange(0, len(pred)).reshape(-1,1), pred.reshape(-1,1)]) \n",
    "            submission_pd = pd.DataFrame(submission, columns=['id','y'])\n",
    "            submission_pd.to_csv('submission.csv', index=None)\n",
    "\n",
    "        return pred\n",
    "    \n",
    "    def predict_stacked(self, write2csv = True):\n",
    "        self.stacked_regressor.fit(self.X_train[:,self.selected_features], self.y_train)\n",
    "        pred = self.stacked_regressor.predict(self.X_test[:,self.selected_features])\n",
    "        \n",
    "        if write2csv is True:\n",
    "            submission = np.hstack([np.arange(0, len(pred)).reshape(-1,1), pred.reshape(-1,1)]) \n",
    "            submission_pd = pd.DataFrame(submission, columns=['id','y'])\n",
    "            submission_pd.to_csv('submission.csv', index=None)\n",
    "\n",
    "        return pred\n",
    "\n",
    "    def do_all(self, n_features = 200):\n",
    "        self.feature_selection(n_features)\n",
    "        pred = self.predict()\n",
    "        return pred\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4fef941c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximelaval/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:302: RuntimeWarning: invalid value encountered in true_divide\n",
      "  corr /= X_norms\n"
     ]
    }
   ],
   "source": [
    "selected_features = features_selection(X_train_0, y_train.ravel(), X_test_0,n_features=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5a1ac3a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>822</th>\n",
       "      <th>823</th>\n",
       "      <th>824</th>\n",
       "      <th>825</th>\n",
       "      <th>826</th>\n",
       "      <th>827</th>\n",
       "      <th>828</th>\n",
       "      <th>829</th>\n",
       "      <th>830</th>\n",
       "      <th>831</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.344446</td>\n",
       "      <td>-0.178186</td>\n",
       "      <td>-0.171544</td>\n",
       "      <td>-0.521170</td>\n",
       "      <td>-0.581863</td>\n",
       "      <td>-0.624325</td>\n",
       "      <td>1.051221</td>\n",
       "      <td>0.884028</td>\n",
       "      <td>0.754139</td>\n",
       "      <td>0.208950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.343369</td>\n",
       "      <td>0.257901</td>\n",
       "      <td>0.039364</td>\n",
       "      <td>-0.706040</td>\n",
       "      <td>-0.657082</td>\n",
       "      <td>-0.058578</td>\n",
       "      <td>-0.396781</td>\n",
       "      <td>-1.160816</td>\n",
       "      <td>-0.578562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.060607</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.405214</td>\n",
       "      <td>-0.634940</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016474</td>\n",
       "      <td>0.021587</td>\n",
       "      <td>0.788090</td>\n",
       "      <td>-0.918248</td>\n",
       "      <td>1.191289</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.290090</td>\n",
       "      <td>-0.076270</td>\n",
       "      <td>0.342912</td>\n",
       "      <td>-0.388688</td>\n",
       "      <td>0.026633</td>\n",
       "      <td>-1.354313</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.901418</td>\n",
       "      <td>1.471716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.321800</td>\n",
       "      <td>0.104225</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.148170</td>\n",
       "      <td>-0.987799</td>\n",
       "      <td>-0.607920</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.015678</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.682024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.226703</td>\n",
       "      <td>0.346362</td>\n",
       "      <td>-0.262848</td>\n",
       "      <td>-0.314427</td>\n",
       "      <td>1.008976</td>\n",
       "      <td>0.350701</td>\n",
       "      <td>0.428638</td>\n",
       "      <td>-1.469588</td>\n",
       "      <td>-0.108832</td>\n",
       "      <td>-0.355467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.460048</td>\n",
       "      <td>-1.893815</td>\n",
       "      <td>-2.519687</td>\n",
       "      <td>0.009301</td>\n",
       "      <td>-0.038495</td>\n",
       "      <td>0.201611</td>\n",
       "      <td>0.055529</td>\n",
       "      <td>0.001583</td>\n",
       "      <td>0.067653</td>\n",
       "      <td>0.098773</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.048343</td>\n",
       "      <td>-2.951128</td>\n",
       "      <td>-2.212513</td>\n",
       "      <td>0.027823</td>\n",
       "      <td>-0.064964</td>\n",
       "      <td>-2.423516</td>\n",
       "      <td>0.071075</td>\n",
       "      <td>-1.347434</td>\n",
       "      <td>-0.118756</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.488470</td>\n",
       "      <td>1.331872</td>\n",
       "      <td>0.013615</td>\n",
       "      <td>-0.716475</td>\n",
       "      <td>-0.279598</td>\n",
       "      <td>-0.346501</td>\n",
       "      <td>-0.304391</td>\n",
       "      <td>0.605764</td>\n",
       "      <td>0.273582</td>\n",
       "      <td>1.654176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026551</td>\n",
       "      <td>0.259718</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.112990</td>\n",
       "      <td>0.416518</td>\n",
       "      <td>-0.023086</td>\n",
       "      <td>0.337956</td>\n",
       "      <td>0.383452</td>\n",
       "      <td>-0.463940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 832 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -0.344446 -0.178186 -0.171544 -0.521170 -0.581863 -0.624325  1.051221   \n",
       "1  1.060607  0.000000  1.405214 -0.634940  0.000000  0.016474  0.021587   \n",
       "2 -0.321800  0.104225  0.000000  2.148170 -0.987799 -0.607920  0.000000   \n",
       "3 -2.460048 -1.893815 -2.519687  0.009301 -0.038495  0.201611  0.055529   \n",
       "4 -0.488470  1.331872  0.013615 -0.716475 -0.279598 -0.346501 -0.304391   \n",
       "\n",
       "        7         8         9    ...       822       823       824       825  \\\n",
       "0  0.884028  0.754139  0.208950  ...  0.000000 -0.343369  0.257901  0.039364   \n",
       "1  0.788090 -0.918248  1.191289  ...  0.000000  1.290090 -0.076270  0.342912   \n",
       "2 -0.015678  0.000000  0.682024  ...  0.226703  0.346362 -0.262848 -0.314427   \n",
       "3  0.001583  0.067653  0.098773  ... -0.048343 -2.951128 -2.212513  0.027823   \n",
       "4  0.605764  0.273582  1.654176  ...  0.026551  0.259718  0.000000  0.000000   \n",
       "\n",
       "        826       827       828       829       830       831  \n",
       "0 -0.706040 -0.657082 -0.058578 -0.396781 -1.160816 -0.578562  \n",
       "1 -0.388688  0.026633 -1.354313  0.000000 -0.901418  1.471716  \n",
       "2  1.008976  0.350701  0.428638 -1.469588 -0.108832 -0.355467  \n",
       "3 -0.064964 -2.423516  0.071075 -1.347434 -0.118756  0.000000  \n",
       "4 -1.112990  0.416518 -0.023086  0.337956  0.383452 -0.463940  \n",
       "\n",
       "[5 rows x 832 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tr= pd.DataFrame(X_train_0)\n",
    "df_tr.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6f8925a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2  15  18  21  23  26  27  29  40  69  77  87  89  92  98 100 101 107\n",
      " 113 114 115 132 133 141 143 144 146 148 151 159 169 172 174 177 193 194\n",
      " 200 202 203 209 213 214 218 220 230 231 232 233 240 242 245 248 254 260\n",
      " 263 272 276 278 283 286 287 288 298 300 306 309 310 312 315 318 319 320\n",
      " 325 326 327 333 334 342 345 349 350 358 359 362 369 370 374 380 381 383\n",
      " 392 395 399 402 410 414 415 425 431 437 440 442 445 452 456 458 465 479\n",
      " 484 485 493 496 502 507 512 517 520 523 528 531 538 542 543 546 547 548\n",
      " 554 558 562 565 568 571 579 590 594 596 602 603 608 610 612 613 614 621\n",
      " 633 636 640 641 642 644 648 649 654 657 659 665 668 670 671 672 675 677\n",
      " 681 685 690 696 702 703 711 712 713 715 720 721 725 726 727 731 734 742\n",
      " 745 748 759 766 768 769 773 774 777 778 780 783 788 790 796 801 817 819\n",
      " 823 824]\n"
     ]
    }
   ],
   "source": [
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6abe5e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data imputation for X_train and X_test, then using SelectKbest to pick up the best 200 features\n",
    "\n",
    "new_train = X_train[:,selected_features]\n",
    "new_test = X_test[:,selected_features]\n",
    "\n",
    "new_train,new_test = standardize_data(new_train,new_test)\n",
    "\n",
    "X_train, X_test = imputation(imputers[5], new_train, new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "da4bd126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(776, 200)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "12bfec4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test =lasso(X_train,y_train,X_test)\n",
    "\n",
    "X_train,y_train = outlier_detection(X_train,y_train)\n",
    "#X_train,X_test = lasso(X_train,y_train,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "342c4bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "samples = X_train.shape[1]\n",
    "print(samples)\n",
    "\n",
    "#estimator 100, learning rate 0.1, max_depth=7\n",
    "xgb4 = XGB(X_train, y_train, X_test)\n",
    "xgb4.feature_selection(n_features=100)\n",
    "pred = xgb4.predict(write2csv=True)\n",
    "\n",
    "#print(r2_score(y_test.ravel(),pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c33f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from hyperopt import fmin, tpe, hp,space_eval,rand,Trials,partial,STATUS_OK\n",
    "\n",
    "def GBM(argsDict):\n",
    "    max_depth = argsDict[\"max_depth\"] + 5\n",
    "    n_estimators = argsDict['n_estimators'] * 5 + 70\n",
    "    learning_rate = argsDict[\"learning_rate\"] * 0.02 + 0.05\n",
    "    subsample = argsDict[\"subsample\"] * 0.1 + 0.6\n",
    "    colsample_bytree = argsDict[\"colsample_bytree\"] * 0.1 + 0.6\n",
    "    min_child_weight = argsDict[\"min_child_weight\"] + 1\n",
    "    gamma = argsDict[\"min_child_weight\"] * 0.1\n",
    "    reg_alpha = argsDict[\"reg_alpha\"] * 0.1\n",
    "    reg_lambda = argsDict[\"reg_lambda\"] * 0.1\n",
    "    print(\"max_depth:\" + str(max_depth))\n",
    "    print(\"n_estimators:\" + str(n_estimators))\n",
    "    print(\"learning_rate:\" + str(learning_rate))\n",
    "    print(\"subsample:\" + str(subsample))\n",
    "    print(\"colsample_bytree:\" + str(colsample_bytree))\n",
    "    print(\"min_child_weight:\" + str(min_child_weight))\n",
    "    print(\"gamma:\" + str(gamma))\n",
    "    print(\"reg_alpha:\" + str(reg_alpha))\n",
    "    print(\"reg_lambda:\" + str(reg_lambda))\n",
    "\n",
    "    gbm = XGBRegressor(learning_rate = learning_rate,\n",
    "                        n_estimators = n_estimators,\n",
    "                        max_depth = max_depth,\n",
    "                        min_child_weight = min_child_weight,\n",
    "                        subsample = subsample,\n",
    "                        colsample_bytree = colsample_bytree,\n",
    "                        gamma = gamma,\n",
    "                        reg_alpha = reg_alpha,\n",
    "                        reg_lambda = reg_lambda\n",
    "    )\n",
    "\n",
    "    metric = cross_val_score(gbm,X_train,y_train,cv=10,scoring=\"r2\") \n",
    "    print(str(metric) + '\\n')\n",
    "    metric_m= metric.mean()\n",
    "    return -metric_m\n",
    "\n",
    "space = {\"max_depth\":hp.randint(\"max_depth\",15),\n",
    "         \"n_estimators\":hp.randint(\"n_estimators\",10),  #[0,1,2,3,4,5] -> [50,]\n",
    "         \"learning_rate\":hp.randint(\"learning_rate\",6),  #[0,1,2,3,4,5] -> 0.05,0.06\n",
    "         \"subsample\":hp.randint(\"subsample\",5),#[0,1,2,3,4] -> [0.6,0.7,0.8,0.9,1.0]\n",
    "         \"colsample_bytree\":hp.randint(\"colsample_bytree\",5),#[0,1,2,3,4] -> [0.6,0.7,0.8,0.9,1.0]\n",
    "         \"min_child_weight\":hp.randint(\"min_child_weight\",7), #[0,1,2,3,4,5,6] -> +1\n",
    "         \"gamma\":hp.randint(\"gamma\", 7), # * 0.1\n",
    "         \"reg_alpha\":hp.randint(\"reg_alpha\", 30), # * 0.1\n",
    "         \"reg_lambda\":hp.randint(\"reg_lambda\", 30), # * 0.1\n",
    "        }\n",
    "algo = partial(tpe.suggest,n_startup_jobs=1)\n",
    "best = fmin(GBM,space,algo=algo,max_evals=200)\n",
    "\n",
    "print(best)\n",
    "print(GBM(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f387e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
