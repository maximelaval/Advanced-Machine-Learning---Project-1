{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342c4bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer \n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy import stats\n",
    "from sklearn import feature_selection\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "X_test = pd.read_csv(\"X_test.csv\", index_col=0).values\n",
    "X_train = pd.read_csv(\"X_train.csv\", index_col=0).values\n",
    "y_train = pd.read_csv(\"y_train.csv\", index_col=0).values\n",
    "\n",
    "## Outlier detection with zscore\n",
    "df_train = pd.DataFrame(X_train)\n",
    "\n",
    "for i in range(X_train.shape[1]):\n",
    "    data_d=df_train[i]\n",
    "    data_d[(np.nan_to_num(np.abs(stats.zscore(data_d, nan_policy='omit')),0) > 3)]=np.nan\n",
    "    df_train[i]=data_d\n",
    "\n",
    "# Outlier detection with filter\n",
    "def filter(df1, df2):\n",
    "  # Filter feature selection\n",
    "  from sklearn.feature_selection import VarianceThreshold \n",
    "\n",
    "\n",
    "  # Step 1: Removing Constant features\n",
    "  constant_filter = VarianceThreshold(threshold=0)\n",
    "  data_constant = constant_filter.fit_transform(df1)\n",
    "  #print(data_constant.shape)\n",
    "  constant_columns = [column for column in df1.columns if column not in df1.columns[constant_filter.get_support()]]\n",
    "  data_cons1 = df1.drop(constant_columns,axis=1)\n",
    "  data_cons2 = df2.drop(constant_columns,axis=1)\n",
    "      \n",
    "  # Step 2: Removing Quasi-Constant Features\n",
    "  qcons_filter = VarianceThreshold(threshold=0.01)\n",
    "  data_qcons = qcons_filter.fit_transform(df1)\n",
    "  #print(data_qcons.shape)\n",
    "  qcons_columns = [column for column in df1.columns if column not in df1.columns[qcons_filter.get_support()]]\n",
    "  data_qcons1 = df1.drop(qcons_columns,axis=1)\n",
    "  data_qcons2 = df2.drop(qcons_columns,axis=1)\n",
    "  data_qcons_t1 = data_qcons1.T\n",
    "  data_qcons_t2 = data_qcons2.T \n",
    "  # Step 3: Removing Duplicate Columns\n",
    "  data_cons_dup1 = data_qcons_t1.drop_duplicates(keep='first').T\n",
    "  data_cons_dup2 = data_qcons_t2.drop_duplicates(keep='first').T\n",
    "  return data_cons_dup1, data_cons_dup2\n",
    "\n",
    "df_test = pd.DataFrame(X_test)\n",
    "X_train, X_test = filter(df_train, df_test)\n",
    "X_train, X_test = X_train.values, X_test.values\n",
    "\n",
    "#Define some imputers\n",
    "imputers = [\n",
    "    SimpleImputer(missing_values=np.nan, strategy='median'),\n",
    "    IterativeImputer(random_state=0, estimator=BayesianRidge()),\n",
    "    IterativeImputer(random_state=0, estimator=DecisionTreeRegressor(max_features=\"sqrt\", random_state=0)),\n",
    "    IterativeImputer(random_state=0, estimator=ExtraTreesRegressor(n_estimators=15, random_state=0, max_depth=7, min_samples_leaf=2)),\n",
    "    IterativeImputer(random_state=0, estimator=KNeighborsRegressor(n_neighbors=15)),\n",
    "    KNNImputer(n_neighbors=10, weights=\"uniform\"),\n",
    "    IterativeImputer(random_state=0, estimator=RandomForestRegressor(n_estimators= 15, random_state = 0, max_depth= 6, min_samples_leaf=2))\n",
    "]\n",
    "\n",
    "def imputation(imputer, X_train, X_test):\n",
    "    imputer.fit(X_train)\n",
    "    X_train_0 = imputer.transform(X_train)\n",
    "    X_test_0 = imputer.transform(X_test)\n",
    "    return X_train_0, X_test_0\n",
    "\n",
    "def features_selection(X_train, y_train, X_test,  n_features):\n",
    "  from sklearn import feature_selection\n",
    "  from sklearn.linear_model import LinearRegression\n",
    "  model = feature_selection.SelectKBest(score_func=feature_selection.f_regression,k=n_features)\n",
    "  model = model.fit(X_train, y_train)\n",
    "  train = model.transform(X_train)\n",
    "  test = model.transform(X_test)\n",
    "\n",
    "  return train, test\n",
    "\n",
    "def outlier_detection(X_train, y_train):\n",
    "    clf = IsolationForest(max_samples=100, random_state = 1, contamination='auto')\n",
    "    preds = clf.fit_predict(X_train)\n",
    "    X_train_1 = X_train[preds==1]\n",
    "    y_train_1 = y_train[preds==1]\n",
    "    return X_train_1, y_train_1\n",
    "\n",
    "class XGB():\n",
    "    def __init__(self, X_train, y_train, X_test):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.n_original_features = X_train.shape[1]\n",
    "        self.selected_features = np.arange(self.n_original_features)\n",
    "\n",
    "        #self.outlier_detection(self.selected_features, self.y_train)\n",
    "\n",
    "        self.regressor = XGBRegressor(max_depth=6,# depth of the tree\n",
    "                                    learning_rate=0.08,\n",
    "                                    n_estimators=100,# number of the tree\n",
    "                                    )\n",
    "\n",
    "\n",
    "    def feature_selection(self, n_features = 200):\n",
    "        self.regressor.fit(self.X_train, self.y_train)\n",
    "        self.selected_features = np.argsort(self.regressor.feature_importances_)[::-1][:n_features]\n",
    "        return self.selected_features\n",
    "\n",
    "    def cross_validation(self, n_split = 8):\n",
    "        ret = cross_val_score(self.regressor, self.X_train[:,self.selected_features], self.y_train, scoring='r2', cv=n_split)\n",
    "        return ret\n",
    "\n",
    "    def predict(self, write2csv = True):\n",
    "        self.regressor.fit(self.X_train[:,self.selected_features], self.y_train)\n",
    "        pred = self.regressor.predict(self.X_test[:,self.selected_features])\n",
    "\n",
    "        if write2csv is True:\n",
    "            submission = np.hstack([np.arange(0, len(pred)).reshape(-1,1), pred.reshape(-1,1)]) \n",
    "            submission_pd = pd.DataFrame(submission, columns=['id','y'])\n",
    "            submission_pd.to_csv('submission.csv', index=None)\n",
    "\n",
    "        return pred\n",
    "\n",
    "    def do_all(self, n_features = 200):\n",
    "        self.feature_selection(n_features)\n",
    "        pred = self.predict()\n",
    "        return pred\n",
    "\n",
    "# data imputation for X_train and X_test, then using SelectKbest to pick up the best 200 features\n",
    "X_train_0_1, X_test_0_1 = imputation(imputers[2], X_train, X_test)\n",
    "X_train_0, X_test_0 = features_selection(X_train_0_1, y_train.ravel(), X_test_0_1,n_features=200)\n",
    "\n",
    "#pd.DataFrame(X_train_0_1).to_csv('x_train_ex.csv',index= None)\n",
    "#pd.DataFrame(y_train).to_csv('y_train_ex.csv',index= None)\n",
    "#pd.DataFrame(X_test_0_1).to_csv('x_test_ex.csv',index= None)\n",
    "\n",
    "\n",
    "#X_test_0 = pd.read_csv(\"X_test_.csv\", index_col=0).values\n",
    "#X_train_ = pd.read_csv(\"X_train_ex.csv\", index_col=0).values\n",
    "#y_train_1 = pd.read_csv(\"y_train.csv\", index_col=0).values\n",
    "#estimator 100, learning rate 0.1, max_depth=7\n",
    "xgb4 = XGB(X_train_0, y_train, X_test_0)\n",
    "xgb4.feature_selection(n_features=200)\n",
    "pred = xgb4.predict(write2csv=True)\n",
    "print(pd.DataFrame(pred))\n",
    "\n",
    "cv_ret = xgb4.cross_validation()\n",
    "print(cv_ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f387e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
